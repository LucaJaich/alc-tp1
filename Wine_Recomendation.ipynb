{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trabajo Práctico N° 2\n",
    "##### Sistemas de Recomendación\n",
    "Facultad de Ciencias Exactas y Naturales\n",
    "\n",
    "Álgebra Lineal Computacional 2°C 2023\n",
    "\n",
    "Luca Jaichenco ~ 591/22 |Mario Sigal Aguirre ~ 157/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Pasos para implementar un sistema de recomendación de vinos\n",
    "\n",
    "Se siguieron los pasos descritos en el trabajo practico y en el archivo auxiliar para la creación de un sistema de recomendación de vinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Descargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('./wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Separar los datos en variables independientes (X) y dependiente (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables independientes:\n",
    "variables_independientes = ['Alcohol', 'Malic_Acid', 'Ash', 'Ash_Alcanity', 'Magnesium',\n",
    "                            'Total_Phenols', 'Flavanoids', 'Nonflavanoid_Phenols',\n",
    "                            'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline']\n",
    "df_wine_independientes = df_wine[variables_independientes]\n",
    "\n",
    "# Variable dependiente:\n",
    "variables_dependientes =['Customer_Segment']\n",
    "df_wine_dependientes = df_wine[variables_dependientes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Normalizar y centrar los datos.\n",
    "Se pide construir una función en python que normalice y centre los valores respecto del promedio. Es decir, aplicar a cada variable independiente:\n",
    "1. $ xi = (X_i - \\bar{X})/s $ \n",
    "\n",
    "2. $ \\bar{X} = (\\sum_{i=1}^{N} X_i) /N  $\n",
    "\n",
    "3. $ s = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N} (X_i - \\bar{X})^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#función que normaliza y centra respecto del promedio \n",
    "def normalizacion(X):# recibe un Data Frame que contenga solamente las variables independientes    \n",
    "    \n",
    "    # inicialización de variables\n",
    "    mean = np.mean(X, axis=0)\n",
    "    s = np.std(X, axis=0)\n",
    "    X_norm = (X - mean) / s\n",
    "    \n",
    "    return X_norm, mean, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alcohol                -8.382808e-16\n",
       "Malic_Acid             -1.197544e-16\n",
       "Ash                    -8.370333e-16\n",
       "Ash_Alcanity           -3.991813e-17\n",
       "Magnesium              -3.991813e-17\n",
       "Total_Phenols           0.000000e+00\n",
       "Flavanoids             -3.991813e-16\n",
       "Nonflavanoid_Phenols    3.592632e-16\n",
       "Proanthocyanins        -1.197544e-16\n",
       "Color_Intensity         2.494883e-17\n",
       "Hue                     1.995907e-16\n",
       "OD280                   3.193450e-16\n",
       "Proline                -1.596725e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm, mean, s = normalizacion(df_wine_independientes)\n",
    "X_norm.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar un conjunto de datos es importante por varias razones:\n",
    "En principio queremos que las variables tengan las mismas escala y mismo rango, pues de no tenerlas, la matriz de covarianza podría verse afectada, dando más peso a las variables con escalas más grandes y haciendo que las variables con rangos más pequeños tengan una contribución mínima. La normalización asegura que todas las variables tengan la misma escala y rango.\n",
    "A su ves  la normalización facilita la interpretación de la matriz de covarianza y de los resultados de PCA ya que como los componentes principales proporcionan información sobre la contribución de cada variable a la variabilidad total, normalizar hace que nos sea posible comparar estas contribuciones de manera optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Calcular la matriz de covarianza\n",
    "$cov(b) = \\frac{b^{*}b}{n-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasamos el data frame a una matriz\n",
    "matriz_wine_norm = df_wine_independientes_norm.values\n",
    "\n",
    "#calculamos la matriz de covarianza\n",
    "wine_cov = (matriz_wine_norm.T @ matriz_wine_norm)/177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de covarianza describe la relación entre las variables de nuestro data frame. Los elementos en la posición $(i,j)$  de la matriz se encuentran entre menos uno y uno [-1,1] y representan la covarianza entre las variables $ X_i$ y $X_j$: \n",
    "Si el elemento es cercano a uno indica una relación positiva, Cuando $X_i$ tiende a ser grande, $X_j$ también tiende a ser grande, y viceversa.\n",
    "Si el elemento es cercano a menos uno indica una relación negativa. Cuando $X_i$ tiende a ser grande,$X_j$ tiende a ser pequeño, y viceversa.\n",
    "Si el elemento es cercano a cero indica que no existe una relación precisa \n",
    "Es de dimension $n \\times n$ y en nuestro caso $ 13 \\times 13. cumple las propiedades de ser Simétrica y Definida Positiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Encontrar el máximo autovalor y el correspondiente autovector de la matriz de covarianza  por el método de la potencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.705850252990422 [ 0.1443294  -0.24518758 -0.00205106 -0.23932041  0.14199204  0.39466085\n",
      "  0.4229343  -0.2985331   0.31342949 -0.0886167   0.29671456  0.37616741\n",
      "  0.28675223]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def metodo_potencia(m, its=100):\n",
    "  \n",
    "    v = np.random.rand(m.shape[0])  # Inicializar un vector aleatorio\n",
    "    for i in range(its):\n",
    "        v = np.dot(m, v)\n",
    "        v = v / np.linalg.norm(v)  # Normalizar el vector en cada iteración\n",
    "    \n",
    "    AutoValor = np.dot(np.dot(m, v), v) / np.dot(v, v) \n",
    "    AutoVector = v\n",
    "    return AutoValor, AutoVector\n",
    "\n",
    "# max_Aval_wine_cov, Avec_de_max_Aval_wine_cov = metodo_potencia(wine_cov)\n",
    "\n",
    "# print(max_Aval_wine_cov, Avec_de_max_Aval_wine_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 4.0] [array([0.70710678, 0.70710678]), array([-0.98994949,  0.14142136])]\n"
     ]
    }
   ],
   "source": [
    "#(f)\n",
    "def todos_Avals_Avecs(A, n):\n",
    "    Avals = []\n",
    "    Avects = []\n",
    "    Aval = 0\n",
    "    Avect = np.zeros(A.shape[0])\n",
    "    for i in range(0,n):\n",
    "        A = A - Aval*np.outer(Avect,Avect)\n",
    "        Aval, Avect = metodo_potencia(A)\n",
    "        Avals.append(round(Aval, 5))\n",
    "        Avects.append(Avect)\n",
    "    return Avals, Avects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(g)\n",
    "# buscamos autovalores y autovectores de la matriz de covarianza\n",
    "# Avals, Avects = todos_Avals_Avects(wine_cov, 13)\n",
    "\n",
    "# Sea V  la matriz con los autovectores por columnas  \n",
    "# V = np.array(Avects).T\n",
    "# # Sea D la matriz diagonal con los autovalores en la diagonal ordenados de mayor a menor\n",
    "# D = np.diag(Avals)\n",
    "\n",
    "# decidimos tomar como los autovalores mas relevantes a los primeros 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia(v1,v2):\n",
    "    x = 0\n",
    "    for i in  range(v1.shape[0]):\n",
    "        x += (v1[i]-v2[i])**2\n",
    "    return np.sqrt(x)\n",
    "\n",
    "\n",
    "def KNN(T_clasif, T_train, Y_train, K): # devuelve Y_estimado\n",
    "    Y_estimado = []\n",
    "    for i in range(len(T_clasif)):\n",
    "        # Calculo las distancias\n",
    "        distancias = []\n",
    "        for j in range(len(T_train)):\n",
    "            distancias.append((distancia(T_clasif[i],T_train[j]), j))\n",
    "        # Ordeno las distancias, manteniendo el indice de la fila\n",
    "        distancias.sort()\n",
    "        # Calculo los resultados\n",
    "        resultados = {\n",
    "            1:0,\n",
    "            2:0,\n",
    "            3:0\n",
    "        }\n",
    "        for k in range(K):\n",
    "            resultados[Y_train[distancias[k][1]]] += 1\n",
    "        # Agrego el resultado que mas veces apareció en los k vecinos mas cercanos\n",
    "        Y_estimado.append(max(resultados, key=resultados.get))\n",
    "    return Y_estimado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los datos en train y test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "# Dividimos el dataframe normalizado en casos de train y en casos de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_wine_independientes_norm, df_wine_dependientes, test_size=0.2, random_state=0)\n",
    "\n",
    "# Definimos la matriz de covarianza para los casos de train\n",
    "X_train_cov = (X_train.T @ X_train)/len(X_train)\n",
    "\n",
    "# buscamos autovalores y autovectores de la matriz de covarianza\n",
    "Avals, Avects = todos_Avals_Avects(X_train_cov, 13)\n",
    "\n",
    "# Sea V  la matriz con los autovectores por columnas  \n",
    "V = np.array(Avects).T\n",
    "\n",
    "CP = 4 # Cantidad de componentes principales\n",
    "K = 5 # Nearest neigbours\n",
    "\n",
    "# Calculo las componentes principales\n",
    "T_train = (X_train @ V[:,:CP]).values # el .values convierte el df en un np array\n",
    "T_test = (X_test @ V[:,:CP]).values\n",
    "\n",
    "Y_train = Y_train['Customer_Segment'].to_numpy() # Agarra la columna 'Customer_Segment' y la convierte en un np array\n",
    "Y_test = Y_test['Customer_Segment'].to_numpy()\n",
    "\n",
    "# Calculo el Y estimado\n",
    "Y_estimado = KNN(T_test, T_train, Y_train, K)\n",
    "\n",
    "# Calculo el error\n",
    "error = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] != Y_estimado[i]:\n",
    "        error += 1\n",
    "error = error/len(Y_test)\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasif_PCA(clasif, X_train, Y_train, CP, K):\n",
    "    X_train_norm, train_mean, train_s = normalizacion(X_train)\n",
    "    clasif_norm = (clasif - train_mean) / train_s\n",
    "\n",
    "    X_cov = (X_train_norm.T @ X_train_norm) / len(X_train_norm)\n",
    "    Avals, Avecs = todos_Avals_Avects(X_cov, X_cov.shape[0])\n",
    "\n",
    "    # Sea V  la matriz con los autovectores por columnas  \n",
    "    V = np.array(Avecs).T\n",
    "\n",
    "    # Calculo las componentes principales\n",
    "    T_train = (X_train_norm @ V[:,:CP])\n",
    "    T_clasif = (clasif_norm @ V[:,:CP])\n",
    "\n",
    "    print(T_train.shape)\n",
    "\n",
    "    return KNN(T_clasif, T_train, Y_train, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df_wine_independientes.values\n",
    "Y = df_wine_dependientes['Customer_Segment'].to_numpy()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# PCA\n",
    "Y_estimado = clasif_PCA(X_test, X_train, Y_train, 13, 5)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] != Y_estimado[i]:\n",
    "        error += 1\n",
    "error = error/len(Y_test)\n",
    "\n",
    "error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
